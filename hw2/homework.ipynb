{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3705663",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from razdel import tokenize, sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8bbc2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_default = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01341538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12534f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_default.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c31bb",
   "metadata": {},
   "source": [
    "**Обучение с дефолтной токенизацией**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3df99cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_def, test_def = train_test_split(data_default, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35af07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_def.reset_index(inplace=True)\n",
    "test_def.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e930971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_def = vectorizer.fit_transform(train_def.comment)\n",
    "X_test_def = vectorizer.transform(test_def.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a766f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12970, 64399), (1442, 64399))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_def.shape, X_test_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fea8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_def = train_def.toxic.values\n",
    "y_test_def = test_def.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e96ef656",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_def = LogisticRegression(C=0.1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e245e76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_def.fit(X_def, y_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c787c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_def.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0da2120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_def = clf_def.predict(X_test_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca3cfa",
   "metadata": {},
   "source": [
    "**Обучение с токенизацией razdel.tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91f5e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natasha_tokens(text):\n",
    "    tokenized = list(tokenize(text))\n",
    "    tokens = list()\n",
    "    for t in tokenized:\n",
    "        tokens.append(t.text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7104fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_razdel = pd.read_csv('labeled.csv')\n",
    "data_default.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "66fb45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdl, test_rdl = train_test_split(data_razdel, test_size=0.1, shuffle=True)\n",
    "train_rdl.reset_index(inplace=True)\n",
    "test_rdl.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd090ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_razdel = CountVectorizer(tokenizer = natasha_tokens)\n",
    "X_rdl = vectorizer_razdel.fit_transform(train_rdl.comment)\n",
    "X_test_rdl = vectorizer_razdel.transform(test_rdl.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf8ef32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rdl = train_rdl.toxic.values\n",
    "y_test_rdl = test_rdl.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69d260eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imphi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rdl = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf_rdl.fit(X_rdl, y_rdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7a101b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rdl.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c5b4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rdl = clf_rdl.predict(X_test_rdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b22c4b",
   "metadata": {},
   "source": [
    "**Метрики для классификатора с дефолтной токенизацией**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4395e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86       962\n",
      "         1.0       0.70      0.83      0.76       480\n",
      "\n",
      "    accuracy                           0.82      1442\n",
      "   macro avg       0.80      0.83      0.81      1442\n",
      "weighted avg       0.84      0.82      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_def, preds_def, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18a598",
   "metadata": {},
   "source": [
    "**Метрики для классификатора с токенизацией razdel.tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4342b4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       952\n",
      "         1.0       0.72      0.85      0.78       490\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.82      0.84      0.83      1442\n",
      "weighted avg       0.85      0.84      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rdl, preds_rdl, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca5db5",
   "metadata": {},
   "source": [
    "Как можно видеть, абсолютно во всем показателям дефолтная токенизация проигрывает razdel.tokenize, пусть и разрыв совсем не большой: 0.01-0.03.\n",
    "\n",
    "**Победитель - модель с токенизацией razdel.tokenize**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa9f76",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f358949",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5b50abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 я  ты  и  только  не  он\n",
      "я и ты           1   1  1       0   0   0\n",
      "ты и я           1   1  1       0   0   0\n",
      "я, я и только я  3   0  1       1   0   0\n",
      "только не я      1   0  0       1   1   0\n",
      "он               0   0  0       0   0   1\n"
     ]
    }
   ],
   "source": [
    "#построение таблицы\n",
    "\n",
    "vals = [[1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0], [3, 0, 1, 1, 0, 0], [1, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 1]]\n",
    "words = [\"я\", \"ты\", \"и\", \"только\", \"не\", \"он\"]\n",
    "docs = ['я и ты', 'ты и я', 'я, я и только я', 'только не я', 'он']\n",
    "tab = pd.DataFrame(vals, columns=words, index=docs)\n",
    "\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "670211ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция нахождения параметра tf\n",
    "\n",
    "def find_tf():\n",
    "    S = list()\n",
    "    for d in docs:\n",
    "        s = len(d.split())\n",
    "        S.append(s)\n",
    "    global tf_list\n",
    "    tf_list = list()\n",
    "    x = 0\n",
    "    for fr in vals:\n",
    "        tf_sublist = [f/S[x] for f in fr]\n",
    "        tf_list.append(tf_sublist)\n",
    "        if x <= len(vals):\n",
    "            x += 1\n",
    "        else:\n",
    "            x = 0    \n",
    "    return tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4900b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция нахождения параметра idf\n",
    "\n",
    "def find_idf():\n",
    "    N = len(docs)\n",
    "    df_list = [0 for d in range(len(vals[0]))]\n",
    "    for val in vals:\n",
    "        for y in range(len(val)):\n",
    "            if val[y] != 0:\n",
    "                df_list[y] += 1\n",
    "            else:\n",
    "                continue\n",
    "    global idf_list\n",
    "    idf_list = [np.log10(N/df) for df in df_list]\n",
    "    return idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ba599a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для нахождения показателя tf-idf\n",
    "\n",
    "def find_tfidf():\n",
    "    global tfidf\n",
    "    tfidf = list()\n",
    "    for tf_sublist in tf_list:\n",
    "        tfidf_sublist = list()\n",
    "        for z in range(len(tf_sublist)):\n",
    "            tfidf_sublist.append(tf_sublist[z]*idf_list[z])\n",
    "        tfidf.append(tfidf_sublist)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6c8944a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        я        ты        и    только       не       он\n",
      "я и ты           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
      "ты и я           0.032303  0.132647  0.07395  0.000000  0.00000  0.00000\n",
      "я, я и только я  0.058146  0.000000  0.04437  0.079588  0.00000  0.00000\n",
      "только не я      0.032303  0.000000  0.00000  0.132647  0.23299  0.00000\n",
      "он               0.000000  0.000000  0.00000  0.000000  0.00000  0.69897\n"
     ]
    }
   ],
   "source": [
    "#вывод финальной таблицы\n",
    "\n",
    "find_tf()\n",
    "find_idf()\n",
    "find_tfidf()\n",
    "\n",
    "tab_new = pd.DataFrame(tfidf, columns=words, index=docs)\n",
    "print(tab_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bc8de",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8961bbf",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46681ef",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ebeb194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\imphi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#загрузка стоп-слов для использования в параметрах классификатора\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')  \n",
    "russian_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94ec70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для вывода на экран топ-10 самых токсичных текстов\n",
    "\n",
    "def show_top10(test_3, probas_3):\n",
    "    sort_commentler_3b = list()\n",
    "    dic_comments_3b = dict(zip(test_3.comment.tolist(), [p[1] for p in probas_3]))\n",
    "    for k, v in sorted(dic_comments_3b.items(), key=lambda item: item[1]):\n",
    "        sort_comment_3b = '{} : {}'.format(k, v)\n",
    "        sort_commentler_3b.append(sort_comment_3b)\n",
    "    j = -1\n",
    "    while j > -11:\n",
    "        print (sort_commentler_3b[j], '\\n')\n",
    "        j-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60724066",
   "metadata": {},
   "source": [
    "**1. Классификатор A: Логистическая регрессия (векторизация CountVectorizer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed77d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3a = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "566526e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3a, test_3a = train_test_split(data_3a, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "154df47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3a.reset_index(inplace=True)\n",
    "test_3a.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5f93aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_3a = CountVectorizer(min_df=10, max_df=0.4, lowercase = False, stop_words = russian_stopwords, ngram_range = (1,2))\n",
    "X_3a = vectorizer_3a.fit_transform(train_3a.comment)\n",
    "X_test_3a = vectorizer_3a.transform(test_3a.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48f325e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12970, 3411), (1442, 3411))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3a.shape, X_test_3a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "69288f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3a = train_3a.toxic.values\n",
    "y_test_3a = test_3a.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8e3e378b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2, class_weight='balanced')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3a = LogisticRegression(C=0.2, class_weight='balanced')\n",
    "clf_3a.fit(X_3a, y_3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5452d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3a.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "209eeee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_3a = clf_3a.predict(X_test_3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0e1a913a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.74      0.81       959\n",
      "         1.0       0.61      0.81      0.70       483\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.75      0.77      0.75      1442\n",
      "weighted avg       0.79      0.76      0.77      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#метрики:\n",
    "print(classification_report(y_test_3a, preds_3a, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cacb1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_3a = clf_3a.predict_proba(X_test_3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "474a4e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Раз уж вакханалия продолжается, давайте в этом треде продолжать собирать ворох банов. Копирую из прошлого треда отсюда и из ответов к нему: Ошибка: Постинг запрещён. Бан: 1067637. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Втр Янв 22 22:00:00 2019. В новом аниме-треде ( завелся один сумасшедший модератор, который удаляет видео, а затем банит пользователей за справедливые вопросы о причине удаления данных видео по надуманным причинам вроде злоупотребления трипкодом аватаркой или обсуждения модерации вне d . Я - один из тех, кто попал под его раздачу. Поэтому, в связи с этим, требую немедленно разбанить меня и остальных, кто стал жертвой модераторского произвола и изгнать с должности модератора этого человека, он профнепригоден. Ошибка постинга: Постинг запрещён. Бан: 1068596. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Птн Янв 25 22:00:00 2019. Какая блядь аватарка, вы в глаза долбитесь? Спасибо Абу. Ошибка постинга: Постинг запрещён. Бан: 1068457. Причина: b 2 - Аватаркочатики в 2d !b. О каких аватаркочатиках может идти речь? Какое 2d я там не был в жизни. Я общался с аноном без пикч на тему треда! Уже и тут пообщатся нельзя? Разбаньте позязя. Несправедливый бан: Постинг запрещён. Бан: 1068078. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Срд Янв 23 22:00:00 2019. Попросил скинуть вебмки по K-on! Анон скинул, я сказал спасибо. Забанили и меня и его. А ещё общалую НЕСПРАВЕДЛИВЫЙ бан. Бан: 1068350. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Бан: 1068074. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Срд Янв 23 22:00:00 2019. Какого хрена мочух банит анонов в Аниме тредах по своему желанию и по пизданутым причинам? Error: Постинг запрещён. Бан: 1068344. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Втр Янв 22 22:00:00 2019. Только что запостил две вебм в вебм тред b , разной тематики, не связанные друг с другом, посты вообще были без текста и трипкода. После второй вебм улетел в бан, тред видимо после этого тоже потёрли. Какое злоупотребление? Может стоит пересмотреть бан? И дебилов которые их выписывают. Постинг запрещён. Бан: 1068070. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b Вы че, ебанутые? Понабрали даунов из вбыдлятне. Это было не аватарка. Меня анон попросил скинуть вебм, что я и сделал. Никаких аватарок и чатиков . Постинг запрещён. Бан: 1067881. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Что за логика у мочи? какая в жопу аватарка? какое злоупотребление пасскодом?! Да, постил я там по одному видео, но это b там и бессмыслицу можно постить, да и никто не жаловался на меня, не писал в треде у бля пошёл на хуй или репортну . Значит если я капчевал капчу с такой же скоростью, то меня не забанили бы? Я деньги вам дал, чтобы эту херню сломанную отменить, а в итоге я получаю пиздюлей только потому, что у меня пасскод предупредил анонов, что они могут получить бан написав что-то в треде. Ошибка постинга: Постинг запрещён. Бан: 1068099. Причина: M Общее 5 - Обсуждение модерации вне d !b. Почему предупреждение посчитал обсуждением модерации? 2ch.hk b res 190040136.html 190040136 Ошибка постинга: Постинг запрещён. Бан: 1068361. Причина: M Общее 5 - Обсуждение модерации вне d !b. Истекает: Втр Янв 22 22:00:00 2019. Обсуждения, КСТАТИ ГОВОРЯ, не было, был скрин, твоего удалённого сообщения. Выпей уже свои таблетки и не заходи на двач. Что за бред какое обсуждение модерации? Я обсуждал аниме-конфоблядей и просто сказал что не застал их. Ошибка постинга: Постинг запрещён. Бан: 1068363. Причина: M Общее 5 - Обсуждение модерации вне d !b. Истекает: Втр Янв 22 22:00:00 Ошибка постинга: Постинг запрещён. Бан: 1069746. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Птн Янв 25 22:00:00 2019. Ошибка постинга: Постинг запрещён. Бан: 1069608. Причина: Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Птн Янв 25 22:00:00 2019. Запостил одну шебм, ахуенно Ошибка постинга: Постинг запрещён. Бан: 1068589. Причина: M Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Птн Янв 25 22:00:00 2019. Ошибка постинга: Постинг запрещён. Бан: 1072740. Причина: Общее 6 - Злоупотребление трипкодом, аватаркой !b. Истекает: Птн Фев 01 22:00:00 2019. За единственное первое же сообщение в треде\n",
      " : 0.9999999985229364 \n",
      "\n",
      "Да Евген просто шлюшка без мнения - то блядь пиндосы ему плохие КОКОКО НА КРОВИ ВТОРОЙ МИРОВОЙ ПОДНЯЛИСЬ (намекая на поставки оружия совкам за бабки, только если бы не муриканское вооружение - сосали бы мы все сейчас длинный болт товарища фюрера) То блядь совки ему плохие - сплошная гебня и гулаги, то сука СОВКИ ХОРОШИЕ КОКОКО - НЕПРАВДА НЕ ВСЯ СТРАНА ГУЛАГ. СУКА АЖ ТРЯСЕТ. А споледний обзор - это вообще КРУЖКА - ЛУКЪЯНЕНКО КОКОКО ВЕЛИЧАЙШИЙ ФАНТАСТ СОВРЕМЕННОСТИ Я ЕЩЕ В 2005 НА НЕГО ДРОЧИЛ ПОКА ЭТО НЕ БЫЛО МЭЙНСТРИМОМ КАК ВАМ НЕ СТЫДНО ЗЛОСТНЫЕ КИНОДЕЛЫ ОБСИРАТЬ И ПОГАНИТЬ ТВОРЧЕСТВО ЭТОГО ВЕЛИКОГО ЧЕЛОВЕКА О ЛУКЪЯНЕНКО КОКОКО КОКОКО ДАЙТЕ Я ЕМУ ОТСОСУ и сука тутже через 15 минут АЙ АЙ АЙ АВТОР САМ ОДОБРИЛ ВСЕ ОТКЛОНЕНИЯ ОТ СУЖЕТА КНИГИ КАК НИХОРОШО АЙ АЙ АЙ - но даже тут побоялся сказать прямо - Лукъяненко продался - нет он увиливает и юлит как змея, ак червь, как червь ПИДОР. БЭДКОМЕДИАН - хуже червя ПИДОРА\n",
      " : 0.9999954616112641 \n",
      "\n",
      "Твоих граждан ? Твои товары ? у ВАС растёт продолжительность жизни? Те гауляйтеры - это ты и твои хозяева-кормильцы, предающие и насилующие российский народ ЕЖЕДНЕВНО И ЕЖЕЧАСНО. Вы торгуете недрами, вы пытаетесь пристроить награбленное подальше от ограбляемогонарода, вы наполнили страну полицаями , защищающими исключительно ваши интересы от российского народа. Вы гоните в НАТО нефть, газ, лес и прочие ресурсы, которые воруете у россиян, вы обложили данью всех от мелких и крупных торговцев, до самозанятых , выживающих в беспределе грабежа и воровства, творимого вами в стране. Вы оплачиваете свои права кровью и потом народа. Свои права по уничтожению этого самого народа. Деньги ВЫ превратили в мерило прав. Право на здравоохранение, образование, защиту и все базовые права ВЫ требуете оплачивать, не считая людьми и гражданами никого, кроме тех,кто это всё оплатит звонкой монетой. И войска НАТО приведёте в страну тоже ВЫ. Своей неудержимой жаждой денег и власти. Так же, как это сделал ваш свято-кровавый николашка , приведя в Россию своих партнёров . Они - ВАШИ партнёры - не мои. Так вот, знайте. Когда ваши партнёры по грабительскому бизнесу придут лишать ВАС вашей доли, и вы, и они будут по другую сторону фронта от меня и российского народа - точно так же, как вы и они ВМЕСТЕ по другую сторону фронта экономического все последние 30 лет. Я за ваши головы не дам и гнилой картошины. Так что, бойтесь не их. Бойтесь нас. Они для меня - просто враги, а ВЫ - ПРЕДАТЕЛИ СОБСТВЕННОГО НАРОДА, говно безродное, НЕЛЮДИ. И только очистив страну от таких как вы, возможно её защитить от них. Запиши на обороте своей методички, и передай по команде.\n",
      " : 0.9999937926662295 \n",
      "\n",
      "Ты либо не знаешь правил русского языка либо шизофреник. Нет - предикатив, отрицающий факт существования в настоящем времени. Ты обосрался, понимаешь? И контекст тут не причем. Ты, глупенький, просто не понимаешь что такое контекст, видимо... По поводу того что Владимир был новгородским князем никто и не спорит, только он не из Новгорода сам был. И это ты, историк мамкин, начал это противопоставление, про то что Владимир из Новгорода приехал и кого то там ебал. Тебя носом и ткнули в то что он был по отцу из Киева, а по матери из Лбюича, и ни то ни другое не Новгород. Но если ты цепляешься за Новгород и считаешь что он имеет отношение к Российской федерации, то ровно такое же отношение к Украине имеет Киев и Любич. Все, свободен, беги зашивать очко шаблон.\n",
      " : 0.9997756960448104 \n",
      "\n",
      "Как известно, у Укр ины (т.е. окр ины), слепленной по пьяни на коленке во 2-м десятилетии XX в., нет истории до XX столетия. Все земли, которые сейчас занимает Укр ина, это русские, румынские, польские и венгерские земли. Напоминаем, что укр инство это сугубо левацкая, антиконсервативная местечково-хуторская идеология, направленная, как и прочие левацкие идеи, на разделение больших наций и поддержание диктата интернацистов. Сторонники бандеровцев (леваков, выступавших за бесклассовое общество и борьбу с капитализмом) и карлика-душителя котов Степана Бандеры, который, как известно, боролся с расизмом, поддерживал Идель-Урал и называл побратимами исламских борцов за свободу из Азербайджана, не пользуются симпатиями у правых европейцев. И это правильно. Попытки заявить о некой отдельной нации неких украинцев это манипуляции, созданные с целью оторвать от русских часть их этнических земель и ослабить в будущем Россию. Только так, чудовищной ложью и тотальной пропагандой, фейковая нация укр инцев , слепленная советскими кукловодами из русских Юга и Киевщины, галичан, поляков, советских румын, славянизированных гуцулов, закарпатских венгров, евреев, татар и многонациональных советских новиопов (а ля Бабченко), может обрести жизнь на русских этнических землях. Разумеется, нет никакого народа укр инцев , как бы одно соседнее failed state ни пыталось их вывести из русских путём обмана, коверканья истории и откровенной фальсификации. Нынешний эксперимент по созданию некой украинской нации можно сравнить разве что с советским экспериментом по созданию нации советской на основании таких же мифов, фейков и откровенного бреда. И маниакальное желание снести все памятники выродку Ленину (Бланку) вас не должно обнадёживать. На смену ему устанавливают памятники такого же левацкого дегенерата-кошкодава Бандеры, чьи руки по локоть в славянской (прежде всего, польской) крови. Заместо совковой лжи про Великую революцию Октября пришла точно такая же наглая ложь про Великую революц ю Г дност абстрагируйтесь от фигуры блогера и посмотрите видео Чем в итоге завершился советский эксперимент, мы все знаем. Ждём закономерного итога эксперимента эльфийского (простите, укр инского ). Разумеется, зомбированные люди будут цепляться до последнего за свои мифы про отельный народ и чужих московитов , но всё это наваждение рано или поздно сгинет, как сгинул Совок со своей мощной идеологией, мифами и фейками.\n",
      " : 0.9996825245992024 \n",
      "\n",
      "Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ\n",
      " : 0.9993626312911453 \n",
      "\n",
      "Жирный, тебе на сосаке не стыдно пиариться? Ты бы хоть поаккуратнее толкал свое говно, палишься. А по теме- говно ты делаешь, лютую хуйню. патлобес\n",
      " : 0.9987514541556599 \n",
      "\n",
      "Предлагаю вашему вниманию поэтические страницы маестра. До тридцати сиянье чуда В тебе, быть может, будет жить Улыбки нежность неоткуда Тебя заставит не забыть Потом морская синь, дороги И быт усталый и глухой Тебя доедут до берлоги И в старость уведут рукой Останутся со мной мгновенья Недокасанья юных рук Недосознанье упоенья Былой любви к тебе, мой друг. 6.03.07. АПОЛОГИЯ ДВИЖЕНИЯ. Среди чернеющих небес Себя найдешь на улице Бредущим по городу Где только снег идет Как ты Другое все иного направленья И сотни тысяч стен домов Тебя встречают В ужасе Ты страшен Поскольку ты идешь Они стоят Тот кто идет всегда опасен И одинок Как этот снег Как эта ночь Огромная удача Что ты не видишь Как ты одинок Но ты уснешь Как это небо станешь Великой темнотой Луна звенит И звезды опадают Как снег, как листопад Куда-то вниз Туда где ты Страниц не различая Запишешь их Листву и звон от звезд И песни стон и лунное дыханье На маятник повяжешь низ Чтоб верх по стрелке шел вперед И только так достигнешь ты себя Своих богов, своих детей Своих последствий И выбор сделаешь на пользу лишь себе 8.03.09. ЧЕЛОВЕК. Такое длинное мгновенье: А дальше эхо и забвенье Что надо нам успеть За этот срок недолгий? Спросить себя: Ты кто? - И дать ответ; Но главное влюбиться: Чтобы ответ мог подтвердиться. 9.01.10. ЮНОСТЬ ПОЭТОВ. Я срезал стебель для своих утех Я гений Значит правом данным от начала Я выбираю жребий тех Кто нужен мне для счастья и причала А, может, для страдания Как агнец богу на закланье На пир души и хищной, и прекрасной Веду я за руку фантомы красоты И каждый ты живешь лишь в мере той Что под руку со мной ведет тебя судьба слепая Ты значим лишь в моих глазах Ты существуешь только как моя болезнь Как озеро испившее нарцисс Как призрак сна настигнувший меня На кромке заколдованного лета Знайте, юность саван воскрешенного поэта 10.02.09. : 0.9953977614615226 \n",
      "\n",
      "Пиздец сука залётная зверушка даже тут насрать успела. Мало того что правил не знает так ещё и права свои соблюдать требует. Аноним 11 03 19 Пнд 17:49:09 500 7217490 Время пятисотого поста 17:49 Твой ёбаный тред БЫЛ СОЗДАН в 17:48. Ты его создал до бамплимита прошлого треда. А теперь иди нахуй тупорылый школьник\n",
      " : 0.9942459997294458 \n",
      "\n",
      "Конечно, конечно! Ты прав! Ой, какой я тупой... Извините, больше не позволю высказывать свое мнение, и свои знания. Как недальновидно-то...\n",
      " : 0.9940828148976606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#десять самых токсичных текстов:\n",
    "show_top10(test_3a, probas_3a)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4313c57",
   "metadata": {},
   "source": [
    "**2. Классификатор B: Наивный байесовский классификатор (векторизация TfidfVectorizer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7cd916f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3b = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69b66d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3b, test_3b = train_test_split(data_3b, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95aa37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3b.reset_index(inplace=True)\n",
    "test_3b.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "593a2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_3b = TfidfVectorizer(min_df=10, max_df=0.4, lowercase = False, stop_words = russian_stopwords, ngram_range = (1,2))\n",
    "X_3b = vectorizer_3b.fit_transform(train_3b.comment)\n",
    "X_test_3b = vectorizer_3b.transform(test_3b.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "07b2a3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 3386)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6095ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3b = train_3b.toxic.values\n",
    "y_test_3b = test_3b.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c782a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, fit_prior=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3b = MultinomialNB(alpha=0.1, fit_prior = False)\n",
    "clf_3b.fit(X_3b, y_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34acbbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3b.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "88fc2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_3b = clf_3b.predict(X_test_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "350388c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.86      0.86       952\n",
      "         1.0       0.73      0.71      0.72       490\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.79      0.79      0.79      1442\n",
      "weighted avg       0.81      0.81      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#метрики:\n",
    "print(classification_report(y_test_3b, preds_3b, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aa23ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_3b = clf_3b.predict_proba(X_test_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4958ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хохлы пидоры. У вас тоже хохол под кроватью?\n",
      " : 0.9996392603305951 \n",
      "\n",
      "соси как хохлы сосут хохол\n",
      " : 0.9995011100824923 \n",
      "\n",
      "НУ ВОТ, ЕРОХИН УЖЕ СВАЛИЛ ЗА БУГОР, А ТЫ ВС СИДИШЬ КАК СЫЧ В СВОЕМ ПО И СИСЯНУ ДОНАТИШЬ!!\n",
      " : 0.9994409363837877 \n",
      "\n",
      "Какие же хохлы всадники, пиздец просто.\n",
      " : 0.9991915849255615 \n",
      "\n",
      "НУ ЧТО, МЕДЛОХИ КАНАВСКИЕ, КАК СОСЕТСЯ, А? АЗАЗАХАХАХАХ!\n",
      " : 0.9990096621772275 \n",
      "\n",
      "РРЯЯЯЯ, КУБАНОИДЫ НЕ РУССКИЕ, НАХУЙ ВЫ НУЖНЫ КАК ЭТО ОТДЕЛЯТЬСЯ, ЭТО ЖЕ ИСКОННО РУССКИЕ ЗЕМЛИ, ВЫХОД К ЧЕРНОМУ МОРЮ, ПЕТР ПЕРВЫЙ, РОССИЮШКА, ИМПЕРИЯ!\n",
      " : 0.9988470351128628 \n",
      "\n",
      "Какие же хохлы новозеландцы дегенераты.\n",
      " : 0.9988248074182684 \n",
      "\n",
      "Э че бля а? Ты че нах бл иди сюда епты.. Ты за царя гнида? Я тя щас грязь растопчу хуесос ептыбля\n",
      " : 0.9985162541304952 \n",
      "\n",
      "Блеаадь, как же обидно когда создаешь тред, пародируешь речь ватников, случайно употребив слово из скрипта, и он скрывается у всех. Пересоздаю. Я много лет тут сижу с вами и обсераю пидорашек хоть я и сам один из них , смеюсь над их смертями, делаю фотожабы с обезьянами. Я-то думал это делают русские русофобы и украинцы, которых процентов 10, поэтому не относился как к чему-то иному как самокритике, самоиронии или справедливому негодованию из-за войны на Донбассе (в конце концов, я считаю украинцев своими братьями и их бугурт небезосновательным). Но меня нахуй осенило когда сначала вернули значки, а потом произошел расстрел мечети в НЗ. Тут до кучи блядских муслимов и они делают это вместе с нами (я думал они слишком беспросветно тупы для того, чтобы интересоваться политикой). Называют русских пидорашками, славщитом. Бляядь, вы действительно думаете вы лучше пидорашек? И вообще славян? Хорошо, я согласен, что кавказские мужчины часто выглядят лучше русских. Но в остальном вы намного хуже даже пидорашек, которые живут окруженные говном и не охуевают, когда с утра, выходя из подъезда на работу, вступают в десятисантиметровую грязь, считая это нормой; которые не имеют никакой солидарности ни по какому признаку, ненавидят друг друга априори, даже своих детей бросают как ёбаные негры, которые скорее сдадут тебя начальству за маячащее вознаграждение (которого им не дадут), если попытаешься подбить людей на забастовку из-за невыплаты зарплаты за полгода; трусливый и терпеливый скот, который барина превозносит и делит людей на касты по признаку наличия и крутости жоповозки; пиздлявые уебки, которые превозносят свой уебищный совок, КОТОРЫЙ ИЗОБРЕЛ ВСЕ В МИРЕ А АМЕРИКАНЦЫ УКРАЛИ!!11, но по факту выясняется, что совок сам практически нихуя не построил и не модернизировал, всё либо по западным проектам с согласия запада, либо с помощью технологического шпионажа. Воистину народ-гной, народ-пидор, народ-мразь, самый подлый народ в мире. Но вы даже на фоне пидорашек выглядите микробами, вы просто ёбаные ничтожества, причем я не пытаюсь вас оскорбить, мои слова действительно отражают вложенный в них изначальный смысл, вы ничто. Да, пидорашки именно такие, какими я описал их выше, они уберхуевые, но они днище цивилизованных народов, тогда как вас к этим цивилизованным народам даже отнести нельзя. Пидорашки хоть что-то изобрели, а если не изобрели, то смогли спиздить и воссоздать технологии и не просто какую-нибудь открывалку банок, а ядерное оружие и энергетику, создали ценящуюся в мире литературу, создали пусть и хуёвую, милитаризованную, построенную на лжи и крови, угнетении и унижении собственных граждан и в конце концов развалившуюся, но сверхдержаву, сделали массу географических открытий и захватили полмира, сейчас воспитывают массу хороших кодеров (правда они скорее воспитываются не благодаря, а вопреки, когда видят какой пиздец вокруг и находят из него такой выход). Не говоря уж об остальных славянах, которых вы тут презрительно называете славщитом и чистильщиками британских туалетов. А по факту поймите, мы-то конечно говно, по сравнению со странами первого мира, с Китаем, ЮК и Японией, даже со странами Южной Америки. Но вы-то блядь даже среди рашкинских регионов самое дно. В прошлом вы (чеченцы, даги и прочие сорта) были просто дикарями, которые нападали на русские караваны и только поэтому вас решили выебать и зохватить. А если говорить о среднеазиатах, которые бугуртят с оккупации, то вы были обычными нищими кочевниками, подтиравшимися камнем и пьющими верблюжью мочу, не имеющими названий народами. Сейчас вас все боятся потому, что если пидорашка сделает в вас пару дырок, защищая себя, то его посадят на бутылку, а если вы убьёте пидорашку, то вам нихуя не будет. И есть мнение, что это сделано специально, чтобы русский воспитывался униженным рабом. Вы унижаете русских детей в школе, потому что вы агрессивные обезьяны, не способные в диалог и возгорающиеся с малейшей искры, и пусть мне тут кто-нибудь заикнется про протопоповскую хуету, дети в школе должны учиться, вдохновляться и выбирать будущую профессию, а не бороться за выживание и дебильный статус в иерархии. И не слушайте дебилов из b , унижение и избиение слабых не делает вас лучше тех, кого вы унижаете, делает защита. Я не люблю выражаться фразами нациков, но вы воистину столетия просто сидели в горах и ебали баранов, вас даже народ-пидор смог захватить. Я знаю, что есть много армянских ученых, музыкантов, известных людей всех сортов, получивших признание в странах первого мира. Я знаю про охуенную грузинскую культуру (которую вы, судя по всему, нагло спиздили в свое время). Но где блядь чеченские я знаю, что вас тут особенно много, поэтому акцентирую внимание именно на вас среди всех муслимских народов СНГ , дагестанские ученые? Открыли дверь? Где государства, культуры? Почему в среднеазиатских парашах работы нет вообще и они все едут уже не в рашку, а в азиатские страны работать заграницу? Хоть что-то есть в вас достойное упоминания, кроме наглости и агрессии? Арийцы, блядь? Самая чистая раса, о чем любят похвастаться чеченцы? Пик 2, вот такие арийцы. Помесь арабов турков, славян и других европеоидов. Алсо, Володин долбит, Пыня хуйло, рашка бантустан, русня народ-гной.\n",
      " : 0.9984303237075884 \n",
      "\n",
      "Лол, совковая пидораха полыхает, но аргументов кроме ДА ВЫ ЖЫ НИЧИГО НИ ПАНИМАИТИ не принес. Рашка сейчас - это совок, который воюет с другими странами (привет, Афганистан), экономика катится в жопу (привет, дефицит), запрещает иностранные товары (привет, совковые пидорахи, готовые дать в жопу за джинсы), и все это на фоне политического болота (привет, Леонид Ильич)\n",
      " : 0.9978827036404053 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#десять самых токсичных текстов:\n",
    "show_top10(test_3b, probas_3b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12317267",
   "metadata": {},
   "source": [
    "**РЕЗУЛЬТАТЫ**\n",
    "\n",
    "Результаты обучения классификаторов очень сильно различаются - ни один из текстов не попал в выборку топ-10 у обеих моделей. Тем не менее, нельзя не отметить, что все найденные моделями тексты являются очень токсичными.\n",
    "\n",
    "У первого классификатора (логистическая регрессия) самые токсичные отличаются значительным размером - похоже, что модель выявила тексты не с максимальным процентом токсичности, а с высоким показателем токсичности в целом, а чем больше текст, тем больше количество токсичных признаков.\n",
    "\n",
    "Второй классификатор показывает куда более короткие тексты, однако во вниманиее стоит взять и тот факт, что модели были обучены не с дефолтными настройками, а имели разные параметры, что и могло повлиять так серьёзно на результат обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68324753",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7794f97",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf9062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621065d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
